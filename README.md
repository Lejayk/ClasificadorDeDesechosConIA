<div align="center">

# ğŸŒâ™»ï¸ Sistema de DetecciÃ³n y ClasificaciÃ³n de Residuos con IA

### *ClasificaciÃ³n Inteligente de Residuos mediante VisiÃ³n Artificial*

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13+-orange.svg)](https://www.tensorflow.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Streamlit](https://img.shields.io/badge/Streamlit-App-red.svg)](https://streamlit.io/)

Proyecto de visiÃ³n artificial para la **Universidad Rafael Urdaneta** orientado a la clasificaciÃ³n automÃ¡tica de residuos (plÃ¡stico, papel, vidrio, orgÃ¡nicos y mÃ¡s) a partir de imÃ¡genes.

[CaracterÃ­sticas](#-caracterÃ­sticas) â€¢ [InstalaciÃ³n](#-instalaciÃ³n) â€¢ [Uso RÃ¡pido](#-uso-rÃ¡pido) â€¢ [DocumentaciÃ³n](#-documentaciÃ³n) â€¢ [Ejemplos](#-ejemplos)

---

</div>

## ğŸ“‹ Tabla de Contenidos

- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [TecnologÃ­as](#-tecnologÃ­as)
- [Arquitectura del Sistema](#-arquitectura-del-sistema)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Estructura de Datos](#-estructura-de-datos)
- [Uso RÃ¡pido](#-uso-rÃ¡pido)
- [Entrenamiento](#-entrenamiento-del-modelo)
- [Pipeline Completo](#-pipeline-completo)
- [EvaluaciÃ³n](#-evaluaciÃ³n-del-modelo)
- [Interfaz Web](#-interfaz-web)
- [Ejemplos de Uso](#-ejemplos-de-uso)
- [DocumentaciÃ³n Adicional](#-documentaciÃ³n-adicional)
- [Contribuir](#-contribuir)

---

## âœ¨ CaracterÃ­sticas

<table>
<tr>
<td width="50%">

### ğŸ¯ Funcionalidades Principales

- âœ… **MÃºltiples Arquitecturas CNN**
  - Custom CNN (ligero, ~5M parÃ¡metros)
  - MobileNetV2 (optimizado para mÃ³viles)
  - ResNet50 (alta precisiÃ³n)
  - EfficientNetB0 (balanceado)

- âœ… **Transfer Learning Avanzado**
  - Pre-entrenamiento con ImageNet
  - Fine-tuning configurable
  - Descongelamiento de capas selectivo

</td>
<td width="50%">

### ğŸš€ Capacidades

- âœ… **Data Augmentation Inteligente**
  - RotaciÃ³n, zoom, flip
  - NormalizaciÃ³n automÃ¡tica
  - Split train/validation/test

- âœ… **Interfaz Completa**
  - CLI para entrenamiento y predicciÃ³n
  - Interfaz web con Streamlit
  - API lista para integraciÃ³n

</td>
</tr>
</table>

### ğŸ·ï¸ CategorÃ­as de Residuos Soportadas

| CategorÃ­a | Emoji | DescripciÃ³n |
|-----------|-------|-------------|
| **PlÃ¡stico** | ğŸ”· | Botellas, envases, bolsas |
| **Papel** | ğŸ“„ | Hojas, revistas, periÃ³dicos |
| **Vidrio** | ğŸ”³ | Botellas, frascos |
| **OrgÃ¡nico** | ğŸŒ± | Restos de comida, plantas |
| **Metal** | âš™ï¸ | Latas, aluminio |
| **CartÃ³n** | ğŸ“¦ | Cajas, empaques |

---

## ğŸ› ï¸ TecnologÃ­as

<div align="center">

| TecnologÃ­a | Uso | VersiÃ³n |
|------------|-----|---------|
| ![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white) | Lenguaje principal | 3.8+ |
| ![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=flat&logo=tensorflow&logoColor=white) | Deep Learning | 2.13+ |
| ![Keras](https://img.shields.io/badge/Keras-D00000?style=flat&logo=keras&logoColor=white) | API de alto nivel | Incluido |
| ![OpenCV](https://img.shields.io/badge/OpenCV-5C3EE8?style=flat&logo=opencv&logoColor=white) | Procesamiento de imÃ¡genes | 4.8+ |
| ![NumPy](https://img.shields.io/badge/NumPy-013243?style=flat&logo=numpy&logoColor=white) | ComputaciÃ³n numÃ©rica | 1.24+ |
| ![Pandas](https://img.shields.io/badge/Pandas-150458?style=flat&logo=pandas&logoColor=white) | AnÃ¡lisis de datos | 2.0+ |
| ![Matplotlib](https://img.shields.io/badge/Matplotlib-11557c?style=flat&logo=python&logoColor=white) | VisualizaciÃ³n | 3.7+ |
| ![Scikit-learn](https://img.shields.io/badge/Scikit--learn-F7931E?style=flat&logo=scikit-learn&logoColor=white) | Machine Learning | 1.3+ |
| ![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=flat&logo=streamlit&logoColor=white) | Interfaz web | 1.30+ |

</div>

---

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SISTEMA DE CLASIFICACIÃ“N                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Entrada de  â”‚   â”‚ Preprocesa-  â”‚   â”‚   Modelo     â”‚
â”‚   Imagen     â”‚â”€â”€â–¶â”‚    miento    â”‚â”€â”€â–¶â”‚     CNN      â”‚
â”‚              â”‚   â”‚              â”‚   â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                     â”‚ ClasificaciÃ³nâ”‚
                                     â”‚  + Confianza â”‚
                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes Principales

```
src/
â”œâ”€â”€ ğŸ“Š data_collection.py    # OrganizaciÃ³n y validaciÃ³n del dataset
â”œâ”€â”€ ğŸ”„ preprocessing.py      # Preprocesamiento y data augmentation
â”œâ”€â”€ ğŸ§  model.py              # Arquitecturas CNN y transfer learning
â”œâ”€â”€ ğŸ“ train.py              # Pipeline de entrenamiento
â”œâ”€â”€ ğŸ“ˆ evaluation.py         # EvaluaciÃ³n y mÃ©tricas
â””â”€â”€ ğŸ¯ detection.py          # Sistema de inferencia
```

---

## ğŸ“¥ InstalaciÃ³n

### Requisitos Previos

> **âš ï¸ Importante:** Se recomienda Python 3.8+ y al menos 8GB de RAM (16GB recomendado para entrenamiento).

### Paso 1: Clonar el Repositorio

```bash
git clone https://github.com/Lejayk/ClasificadorDeDesechosConIA.git
cd ClasificadorDeDesechosConIA
```

### Paso 2: Crear Entorno Virtual (Recomendado)

```bash
# Linux/Mac
python3 -m venv venv
source venv/bin/activate

# Windows
python -m venv venv
venv\Scripts\activate
```

### Paso 3: Instalar Dependencias

```bash
pip install -r requirements.txt
```

### Paso 4: Verificar InstalaciÃ³n

```bash
python setup.py
```

---

## ğŸ“ Estructura de Datos

Organiza el dataset por carpetas de clase:

```text
data/
  raw/
    plastico/
    papel/
    vidrio/
    organico/
```


Organiza tu dataset por carpetas de clase. El sistema detectarÃ¡ automÃ¡ticamente las categorÃ­as:

```
ğŸ“‚ data/
â”œâ”€â”€ ğŸ“‚ raw/                    # Datos originales para entrenamiento
â”‚   â”œâ”€â”€ ğŸ“‚ plastico/          # ImÃ¡genes de plÃ¡stico
â”‚   â”‚   â”œâ”€â”€ img001.jpg
â”‚   â”‚   â”œâ”€â”€ img002.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ ğŸ“‚ papel/             # ImÃ¡genes de papel
â”‚   â”œâ”€â”€ ğŸ“‚ vidrio/            # ImÃ¡genes de vidrio
â”‚   â”œâ”€â”€ ğŸ“‚ organico/          # ImÃ¡genes de orgÃ¡nicos
â”‚   â”œâ”€â”€ ğŸ“‚ metal/             # ImÃ¡genes de metal (opcional)
â”‚   â””â”€â”€ ğŸ“‚ carton/            # ImÃ¡genes de cartÃ³n (opcional)
â”‚
â””â”€â”€ ğŸ“‚ processed/             # Datos procesados (generado automÃ¡ticamente)
    â””â”€â”€ ğŸ“‚ split/
        â”œâ”€â”€ ğŸ“‚ train/         # 80% entrenamiento
        â””â”€â”€ ğŸ“‚ test/          # 20% prueba
```

> **ğŸ’¡ Consejo:** Se recomienda un mÃ­nimo de 100-200 imÃ¡genes por categorÃ­a (idealmente 500+) para mejores resultados.

---

## ğŸš€ Uso RÃ¡pido

### OpciÃ³n 1: Pipeline Completo (Recomendado)

Ejecuta todo el proceso en un solo comando:

```bash
python run_pipeline.py \
    --raw-dir data/raw \
    --epochs 20 \
    --batch-size 32 \
    --overwrite-split
```

Este comando ejecutarÃ¡:
1. âœ… ValidaciÃ³n del dataset
2. âœ… DivisiÃ³n train/test (80/20)
3. âœ… Entrenamiento del modelo
4. âœ… EvaluaciÃ³n automÃ¡tica
5. âœ… GeneraciÃ³n de reportes

### OpciÃ³n 2: Paso a Paso

#### 1ï¸âƒ£ Entrenar el Modelo

```bash
python train_model.py \
    --data-dir data/raw \
    --epochs 20 \
    --batch-size 32
```

#### 2ï¸âƒ£ Evaluar el Modelo

```bash
python evaluate_model.py \
    --test-dir data/test \
    --model models/waste_classifier.h5
```

#### 3ï¸âƒ£ Clasificar una Imagen

```bash
python predict.py --image path/to/image.jpg
```

---

## ğŸ“ Entrenamiento del Modelo

### Entrenamiento BÃ¡sico

El script `train_model.py` implementa **Transfer Learning** con MobileNetV2 pre-entrenado en ImageNet:

```bash
python train_model.py --data-dir data/raw --epochs 20 --batch-size 32
```

### Entrenamiento Avanzado con Fine-Tuning

Para mejores resultados, usa entrenamiento en dos fases:

```bash
python train_model.py \
    --data-dir data/raw \
    --architecture mobilenet \
    --epochs 30 \
    --fine-tune-epochs 10 \
    --learning-rate 0.001 \
    --fine-tune-learning-rate 0.00001 \
    --batch-size 32
```

### CaracterÃ­sticas del Entrenamiento

| CaracterÃ­stica | DescripciÃ³n |
|----------------|-------------|
| **Data Augmentation** | RotaciÃ³n, zoom, flip horizontal, shifts |
| **Preprocesamiento** | Resize a 224x224, normalizaciÃ³n |
| **Split** | 80% entrenamiento, 20% validaciÃ³n |
| **Callbacks** | Early stopping, reducciÃ³n de LR, checkpoints |
| **Transfer Learning** | ImageNet pre-entrenado |

### Artefactos Generados

DespuÃ©s del entrenamiento, se generan:

- `models/waste_classifier.h5` - Modelo entrenado
- `models/training_history.csv` - Historial de mÃ©tricas
- `models/class_indices.json` - Mapeo de Ã­ndices a clases

---

## ğŸ”„ Pipeline Completo

### EjecuciÃ³n BÃ¡sica

```bash
python run_pipeline.py \
    --raw-dir data/raw \
    --epochs 20 \
    --batch-size 32 \
    --overwrite-split
```

### EjecuciÃ³n con Fine-Tuning (Recomendado)

```bash
python run_pipeline.py \
    --raw-dir data/raw/dataset-resized \
    --epochs 20 \
    --fine-tune-epochs 10 \
    --base-learning-rate 0.001 \
    --fine-tune-learning-rate 0.00001 \
    --unfreeze-layers 30 \
    --batch-size 32 \
    --overwrite-split
```

### Proceso del Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. ValidaciÃ³n del Dataset por Carpetas de Clase       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Split Train/Test Reproducible (80/20)              â”‚
â”‚     â””â”€â–¶ data/processed/split/                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Entrenamiento con train_model.py                   â”‚
â”‚     â””â”€â–¶ sobre data/processed/split/train               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. EvaluaciÃ³n AutomÃ¡tica con evaluate_model.py        â”‚
â”‚     â””â”€â–¶ sobre data/processed/split/test                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Reporte de Split en models/split_report.json       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š EvaluaciÃ³n del Modelo


El script `evaluate_model.py` realiza una evaluaciÃ³n completa del modelo:

```bash
python evaluate_model.py \
    --test-dir data/test \
    --model models/waste_classifier.h5
```

### MÃ©tricas Calculadas

<table>
<tr>
<td width="50%">

**ğŸ“ˆ MÃ©tricas Globales**
- Accuracy total
- PÃ©rdida (Loss)
- Precision macro/micro
- Recall macro/micro
- F1-Score

</td>
<td width="50%">

**ğŸ“Š MÃ©tricas por Clase**
- Precision por categorÃ­a
- Recall por categorÃ­a
- F1-Score por categorÃ­a
- Support (muestras)

</td>
</tr>
</table>

### Visualizaciones Generadas

Todas las visualizaciones se guardan en `models/evaluation/`:

| Archivo | DescripciÃ³n |
|---------|-------------|
| `confusion_matrix.png` | Matriz de confusiÃ³n normalizada |
| `classification_report.txt` | Reporte detallado por clase |
| `metrics_summary.csv` | Resumen de mÃ©tricas en CSV |
| `training_history.png` | GrÃ¡ficas de Accuracy y Loss |

### Ejemplo de Salida

```
EvaluaciÃ³n del Modelo
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Accuracy Global: 94.32%
Loss: 0.1845

MÃ©tricas por Clase:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PlÃ¡stico   - Precision: 96.1%  Recall: 94.8%
Papel      - Precision: 93.5%  Recall: 95.2%
Vidrio     - Precision: 92.8%  Recall: 91.5%
OrgÃ¡nico   - Precision: 95.2%  Recall: 96.0%
```

---

## ğŸŒ Interfaz Web

### Lanzar la AplicaciÃ³n Streamlit

La aplicaciÃ³n web permite clasificar imÃ¡genes de forma interactiva:

```bash
streamlit run app.py
```

La aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en `http://localhost:8501`

### CaracterÃ­sticas de la Interfaz

- ğŸ“¤ **Carga de imÃ¡genes** (JPG, JPEG, PNG)
- ğŸ¯ **PredicciÃ³n en tiempo real**
- ğŸ“Š **VisualizaciÃ³n de confianza** (top-3 predicciones)
- ğŸ“ˆ **GrÃ¡fico de barras** con distribuciÃ³n de probabilidades
- ğŸ–¼ï¸ **Vista previa** de la imagen cargada

### GuÃ­a RÃ¡pida de Uso

1. **Inicia la aplicaciÃ³n**
   ```bash
   streamlit run app.py
   ```

2. **Verifica que existe el modelo**
   - Debe existir: `models/waste_classifier.h5`
   - Debe existir: `models/class_indices.json`

3. **Carga una imagen**
   - Clic en "Selecciona una imagen"
   - Elige una foto de residuo

4. **ObtÃ©n la predicciÃ³n**
   - La clase predicha aparecerÃ¡ con su porcentaje de confianza
   - VerÃ¡s un grÃ¡fico con las top-3 predicciones

> **ğŸ’¡ Tip:** Si la aplicaciÃ³n no se abre automÃ¡ticamente, copia la URL que aparece en la terminal y pÃ©gala en tu navegador.

---

## ğŸ’» Ejemplos de Uso

### Ejemplo 1: ClasificaciÃ³n Simple

```bash
python predict.py --image test_images/botella_plastico.jpg
```

**Salida:**
```
ğŸ¯ PredicciÃ³n: PLÃSTICO
ğŸ“Š Confianza: 98.45%
```

### Ejemplo 2: Top-K Predicciones

```bash
python predict.py --image test_images/lata.jpg --top-k 3
```

**Salida:**
```
Top 3 Predicciones:
1. Metal    - 95.2%
2. PlÃ¡stico - 3.1%
3. Vidrio   - 1.2%
```

### Ejemplo 3: Con VisualizaciÃ³n

```bash
python predict.py \
    --image test_images/botella.jpg \
    --output resultado.png \
    --top-k 3
```

Genera una imagen con la predicciÃ³n visualizada.

### Ejemplo 4: Uso ProgramÃ¡tico en Python

```python
from src.detection import WasteDetector

# Inicializar detector
detector = WasteDetector(
    model_path='models/waste_classifier.h5',
    class_mapping_path='models/class_indices.json'
)

# Clasificar imagen
results = detector.predict('imagen.jpg', top_k=3)

# Mostrar resultados
for i, result in enumerate(results, 1):
    print(f"{i}. {result['class']}: {result['percentage']:.2f}%")
```

### Ejemplo 5: PredicciÃ³n en Lote

```python
from src.detection import WasteDetector

detector = WasteDetector(
    model_path='models/waste_classifier.h5',
    class_mapping_path='models/class_indices.json'
)

# Lista de imÃ¡genes
images = ['img1.jpg', 'img2.jpg', 'img3.jpg']

# Procesar en lote
results = detector.batch_predict(images)

for result in results:
    if 'error' not in result:
        pred = result['prediction']
        print(f"{result['image_path']}: {pred['class']} ({pred['percentage']:.1f}%)")
```

---

## ğŸ“š DocumentaciÃ³n Adicional

Para informaciÃ³n mÃ¡s detallada, consulta:

| Documento | DescripciÃ³n |
|-----------|-------------|
| ğŸ“– [EJEMPLOS.md](EJEMPLOS.md) | Ejemplos detallados de uso y cÃ³digo |
| ğŸ”§ [PROJECT_SUMMARY.md](PROJECT_SUMMARY.md) | Resumen tÃ©cnico del proyecto |
| ğŸ““ [notebooks/](notebooks/) | Jupyter notebooks interactivos |
| ğŸ“ [docs/](docs/) | DocumentaciÃ³n tÃ©cnica adicional |

---

## ğŸ”§ ParÃ¡metros de ConfiguraciÃ³n

### `train_model.py`

```bash
python train_model.py [OPTIONS]
```

| ParÃ¡metro | DescripciÃ³n | Default |
|-----------|-------------|---------|
| `--data-dir` | Directorio del dataset | `data/raw` |
| `--epochs` | NÃºmero de Ã©pocas | `50` |
| `--batch-size` | TamaÃ±o del lote | `32` |
| `--architecture` | Arquitectura CNN | `mobilenet` |
| `--learning-rate` | Tasa de aprendizaje | `0.001` |
| `--model-output` | Ruta del modelo `.h5` | `models/waste_classifier.h5` |
| `--history-output` | Historial `.csv` | `models/training_history.csv` |
| `--classes-output` | Mapeo de clases `.json` | `models/class_indices.json` |

### `evaluate_model.py`

```bash
python evaluate_model.py [OPTIONS]
```

| ParÃ¡metro | DescripciÃ³n | Default |
|-----------|-------------|---------|
| `--test-dir` | Dataset de prueba | `data/test` |
| `--model` | Modelo entrenado | `models/waste_classifier.h5` |
| `--classes` | Archivo de clases | `models/class_indices.json` |
| `--history` | Historial de entrenamiento | `models/training_history.csv` |
| `--output-dir` | Carpeta de resultados | `models/evaluation/` |

### `predict.py`

```bash
python predict.py [OPTIONS]
```

| ParÃ¡metro | DescripciÃ³n | Default |
|-----------|-------------|---------|
| `--image` | Ruta de la imagen | *Requerido* |
| `--model` | Modelo a usar | `models/waste_classifier.h5` |
| `--classes` | Archivo de clases | `models/class_indices.json` |
| `--top-k` | Top K predicciones | `1` |
| `--threshold` | Umbral de confianza | `0.0` |
| `--output` | Guardar resultado visualizado | `None` |

---

## ğŸ’¡ Consejos y Mejores PrÃ¡cticas

<table>
<tr>
<td width="50%">

### ğŸ“Š Datos

- âœ… MantÃ©n datasets **balanceados** (similar cantidad por clase)
- âœ… MÃ­nimo **100-200 imÃ¡genes** por categorÃ­a
- âœ… Ideal **500+ imÃ¡genes** por categorÃ­a
- âœ… Usa **imÃ¡genes variadas** (diferentes Ã¡ngulos, iluminaciÃ³n)
- âœ… Separa datos de **test** (nunca usados en entrenamiento)

</td>
<td width="50%">

### ğŸ“ Entrenamiento

- âœ… Usa **data augmentation** para mÃ¡s variabilidad
- âœ… Comienza con **learning rate de 0.001**
- âœ… Ajusta **batch size** segÃºn tu RAM/GPU (16, 32, 64)
- âœ… Empieza con **30-50 Ã©pocas**
- âœ… El **early stopping** pararÃ¡ si no hay mejora

</td>
</tr>
</table>

---

## âš ï¸ SoluciÃ³n de Problemas

### Error: No module named 'tensorflow'

```bash
pip install tensorflow>=2.13.0
```

### Error: Out of memory

```bash
# Reducir batch size
python train_model.py --batch-size 16
```

### Bajo Accuracy

- ğŸ“Š Recopilar mÃ¡s datos
- ğŸ”„ Entrenar por mÃ¡s Ã©pocas
- ğŸ§  Probar transfer learning (mobilenet, resnet)
- âœ… Verificar que los datos estÃ©n bien etiquetados
- ğŸ” Revisar balance de clases

### Modelo Muy Lento

- ğŸ“± Usar **MobileNetV2** para inferencia rÃ¡pida
- ğŸ”½ Reducir tamaÃ±o de imagen a **128x128**
- âš¡ Optimizar modelo con **TensorFlow Lite**
- ğŸ–¥ï¸ Usar GPU para entrenamiento

---

## ğŸ¤ Contribuir

Â¡Las contribuciones son bienvenidas! Si deseas contribuir:

1. ğŸ´ Fork el repositorio
2. ğŸŒ¿ Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. ğŸ’¾ Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. ğŸ“¤ Push a la rama (`git push origin feature/AmazingFeature`)
5. ğŸ”„ Abre un Pull Request

---

## ğŸ“ Notas Importantes

> **â„¹ï¸ DetecciÃ³n AutomÃ¡tica de Clases**
> 
> Si cambias las clases del dataset, el sistema las detecta automÃ¡ticamente desde las carpetas. No necesitas modificar el cÃ³digo.

> **ğŸ”§ ConfiguraciÃ³n por Defecto**
> 
> La aplicaciÃ³n web usa `models/waste_classifier.h5` y `models/class_indices.json` por defecto. AsegÃºrate de que estos archivos existan antes de ejecutar la interfaz.

> **ğŸ¯ ReutilizaciÃ³n del CÃ³digo**
> 
> La inferencia estÃ¡ centralizada en `src/detection.py` (`WasteDetector`), por lo que puedes reutilizar la misma lÃ³gica en:
> - Streamlit (`app.py`)
> - CLI (`predict.py`)
> - API REST (FastAPI/Flask)
> - AplicaciÃ³n de escritorio (Tkinter/PyQt)

---

## ğŸ“œ Licencia

Este proyecto estÃ¡ desarrollado para la **Universidad Rafael Urdaneta** como proyecto acadÃ©mico.

---

## ğŸ™ Agradecimientos

- Universidad Rafael Urdaneta
- TensorFlow y Keras por las herramientas de Deep Learning
- La comunidad de cÃ³digo abierto

---

<div align="center">

### â­ Si este proyecto te fue Ãºtil, considera darle una estrella â­

**Desarrollado con â¤ï¸ para la clasificaciÃ³n inteligente de residuos**

[ğŸ” Volver arriba](#-sistema-de-detecciÃ³n-y-clasificaciÃ³n-de-residuos-con-ia)

</div>
